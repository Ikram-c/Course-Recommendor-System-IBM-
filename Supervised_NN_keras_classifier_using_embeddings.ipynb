{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Surpress any warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import string\n",
    "\n",
    "\n",
    "# Read csvs\n",
    "rating_df = pd.read_csv('ratings.csv')\n",
    "user_emb = pd.read_csv('user_embeddings.csv')\n",
    "item_emb = pd.read_csv('course_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes to substitute user and items from ids with their embedding vectors\n",
    "merged_df = pd.merge(rating_df, user_emb, how='left', on='user').fillna(0)\n",
    "merged_df = pd.merge(merged_df, item_emb, how='left', on='item').fillna(0)\n",
    "# Element-wise add user features (column labels starting with \"UFeature\") and item features (CFeature)\n",
    "u_features = [f\"UFeature{i}\" for i in range(16)]\n",
    "c_features = [f\"CFeature{i}\" for i in range(16)]\n",
    "user_embeddings = merged_df[u_features]\n",
    "course_embeddings = merged_df[c_features]\n",
    "ratings = merged_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the two feature columns using element-wise add\n",
    "interaction_dataset = user_embeddings + course_embeddings.values\n",
    "interaction_dataset.columns = [f\"Feature{i}\" for i in range(16)]\n",
    "interaction_dataset['rating'] = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use LabelEncoder to encode rating into categorical\n",
    "X = interaction_dataset.iloc[:, :-1] \n",
    "y_raw = interaction_dataset.iloc[:, -1] \n",
    "# Transform column into cat\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_raw.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, layers, units):\n",
    "  # Define the model architecture\n",
    "    model = keras.Sequential()\n",
    "    for layer in range(layers):\n",
    "        model.add(keras.layers.Dense(units, input_shape=(input_shape,), activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # Compile the model with an Adam optimizer, a binary cross-entropy loss function, and the F1 metric\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KerasClassifier object that wraps the model\n",
    "model_wrapper = KerasClassifier(build_fn=build_model, input_shape=X.shape[1])\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# Create a KerasClassifier object that wraps the model\n",
    "model_wrapper = KerasClassifier(build_fn=build_model, input_shape=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a parameter grid for the number of layers and units\n",
    "param_grid = {\n",
    "    'layers': [1, 2, 3],\n",
    "    'units': [32, 64, 128]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV object to search over the parameter grid and define the 3 models\n",
    "\n",
    "# Model 1\n",
    "grid_search_1 = GridSearchCV(estimator=model_wrapper, param_grid=param_grid, cv=3, scoring='f1_micro')\n",
    "\n",
    "# Model 2\n",
    "grid_search_2 = GridSearchCV(estimator=model_wrapper, param_grid=param_grid, cv=3, scoring='f1_micro')\n",
    "\n",
    "# Model 3\n",
    "grid_search_3 = GridSearchCV(estimator=model_wrapper, param_grid=param_grid, cv=3, scoring='f1_micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_1.fit(X_train, y_train, epochs = 20)\n",
    "\n",
    "# best parameters and score\n",
    "gs_best_param = grid_search_1.best_params_\n",
    "gs_best_score = grid_search_1.best_score_\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_1.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set using F1 score\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1_model_1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_2.fit(X_train, y_train, epochs = 50)\n",
    "\n",
    "# best parameters and score\n",
    "gs_best_param = grid_search_2.best_params_\n",
    "gs_best_score = grid_search_2.best_score_\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_2.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set using F1 score\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1_model_2 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_3.fit(X_train, y_train, epochs = 100)\n",
    "\n",
    "# best parameters and score\n",
    "gs_best_param = grid_search_3.best_params_\n",
    "gs_best_score = grid_search_3.best_score_\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search_3.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set using F1 score\n",
    "y_pred = best_model.predict(X_test)\n",
    "f1_model_3 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_values = [f1_model_1, f1_model_2, f1_model_3]\n",
    "\n",
    "maximum = max(f1_values)\n",
    "position = f1_values.index(maximum)\n",
    "minimum = min(f1_values)\n",
    "print(maximum)\n",
    "print(minimum)\n",
    "print(f1_values[position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_names = [\"f1_model_1\", \"f1_model_2\", \"f1_model_3\"]\n",
    "# create a dataframe with the values and names\n",
    "df_f1 = pd.DataFrame({'f1_score (higher the better)': f1_values, 'f1_model': f1_names})\n",
    "df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seaborn to plot the bar chart\n",
    "sns.barplot(x='f1_model', y='f1_score (higher the better)', data=df_f1)\n",
    "plt.ylim(minimum, maximum)\n",
    "plt.title('f1_values')\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c31c2c93585b55e010b9381178aeeb9bb3aa7fa708fada384ae012c2fbd9b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
